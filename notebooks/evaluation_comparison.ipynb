{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Uses the ratings json from the survey_analysis notebook\n",
    "as the basis of what to analyze\n",
    "\"\"\"\n",
    "\n",
    "import importlib\n",
    "import json\n",
    "import file_handling as fh\n",
    "import compute_npmi\n",
    "importlib.reload(compute_npmi)\n",
    "from compute_npmi import compute_npmi_at_n, compute_npmi_at_n_for_topic\n",
    "\n",
    "\n",
    "def get_npmi_scores(topics_json, ref_vocab_file, ref_counts_file):\n",
    "    if type(topics_json) not in (tuple, list):\n",
    "        topics_json = (topics_json)\n",
    "        \n",
    "    ref_vocab = fh.read_json(ref_vocab_file)\n",
    "    ref_counts = fh.load_sparse(ref_counts_file).tocsc()\n",
    "\n",
    "    return_list = []\n",
    "    for topic_file in topics_json:\n",
    "        topics = [line[\"terms\"] for line in json.load(open(topics_json))]\n",
    "\n",
    "        npmi_by_topic = []\n",
    "        for topic in topics:\n",
    "            topic_avg_npmi = compute_npmi_at_n_for_topic(topic, ref_vocab, ref_counts, n=10, cols_to_skip=0)\n",
    "            npmi_by_topic.append(topic_avg_npmi)\n",
    "            print(\"topic_avg_npmi: \", topic_avg_npmi)\n",
    "        return_list.append(npmi_by_topic)\n",
    "            \n",
    "    return return_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_npmi_scores = get_npmi_scores(\n",
    "    topics_json = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/news_ratings.json\",\n",
    "    ref_vocab_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/news_group.vocab.json\",\n",
    "    ref_counts_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/news_group.npz\"\n",
    ")\n",
    "news_npmi_scores_oct18 = get_npmi_scores(\n",
    "    topics_json = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/oct_18/news_oct_18_ratings.json\",\n",
    "    ref_vocab_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/news_group.vocab.json\",\n",
    "    ref_counts_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/news_group.npz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_npmi_scores = get_npmi_scores(\n",
    "    topics_json = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/leg_ratings.json\",\n",
    "    ref_vocab_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/115_legislation.vocab.json\",\n",
    "    ref_counts_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/115_legislation.npz\"\n",
    ")\n",
    "print(leg_npmi_scores)\n",
    "\n",
    "leg_npmi_scores_oct18 = get_npmi_scores(\n",
    "    topics_json = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/oct_18/leg_oct_18_ratings.json\",\n",
    "    ref_vocab_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/115_legislation.vocab.json\",\n",
    "    ref_counts_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/115_legislation.npz\"\n",
    ")\n",
    "print(leg_npmi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_npmi_scores = get_npmi_scores(\n",
    "    topics_json = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/covid_ratings.json\",\n",
    "    ref_vocab_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/covid.vocab.json\",\n",
    "    ref_counts_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/covid.npz\"\n",
    ")\n",
    "covid_npmi_scores_oct18 = get_npmi_scores(\n",
    "    topics_json = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/oct_18/covid_oct_18_ratings.json\",\n",
    "    ref_vocab_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/covid.vocab.json\",\n",
    "    ref_counts_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/covid.npz\"\n",
    ")\n",
    "print(covid_npmi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_news_npmi_scores = get_npmi_scores(\n",
    "    topics_json = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/news_ratings.json\",\n",
    "    ref_vocab_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/wiki_ref_counts.vocab.json\",\n",
    "    ref_counts_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/wiki_ref_counts.npz\"\n",
    ")\n",
    "wiki_news_npmi_scores_oct18 = get_npmi_scores(\n",
    "    topics_json = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/oct_18/news_oct_18_ratings.json\",\n",
    "    ref_vocab_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/wiki_ref_counts.vocab.json\",\n",
    "    ref_counts_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/wiki_ref_counts.npz\"\n",
    ")\n",
    "print(wiki_news_npmi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_leg_npmi_scores = get_npmi_scores(\n",
    "    topics_json = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/leg_ratings.json\",\n",
    "    ref_vocab_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/wiki_ref_counts.vocab.json\",\n",
    "    ref_counts_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/wiki_ref_counts.npz\"\n",
    ")\n",
    "wiki_leg_npmi_scores_oct18 = get_npmi_scores(\n",
    "    topics_json = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/oct_18/leg_oct_18_ratings.json\",\n",
    "    ref_vocab_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/wiki_ref_counts.vocab.json\",\n",
    "    ref_counts_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/wiki_ref_counts.npz\"\n",
    ")\n",
    "print(wiki_leg_npmi_scores)\n",
    "wiki_covid_npmi_scores = get_npmi_scores(\n",
    "    topics_json = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/covid_ratings.json\",\n",
    "    ref_vocab_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/wiki_ref_counts.vocab.json\",\n",
    "    ref_counts_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/wiki_ref_counts.npz\"\n",
    ")\n",
    "wiki_covid_npmi_scores_oct18 = get_npmi_scores(\n",
    "    topics_json = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/oct_18/covid_oct_18_ratings.json\",\n",
    "    ref_vocab_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/wiki_ref_counts.vocab.json\",\n",
    "    ref_counts_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/wiki_ref_counts.npz\"\n",
    ")\n",
    "print(wiki_covid_npmi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "news_topics = json.load(open(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/news_ratings.json\"))\n",
    "leg_topics = json.load(open(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/leg_ratings.json\"))\n",
    "covid_topics = json.load(open(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/covid_ratings.json\"))\n",
    "\n",
    "news_topics_oct_18 = json.load(open(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/oct_18/news_oct_18_ratings.json\"))\n",
    "leg_topics_oct_18 = json.load(open(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/oct_18/leg_oct_18_ratings.json\"))\n",
    "covid_topics_oct_18 = json.load(open(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/oct_18/covid_oct_18_ratings.json\"))\n",
    "\n",
    "news_observed_avgs = [np.mean(topic[\"observed_ratings\"]) for topic in news_topics]\n",
    "leg_observed_avgs = [np.mean(topic[\"observed_ratings\"]) for topic in leg_topics]\n",
    "covid_observed_avgs = [np.mean(topic[\"observed_ratings\"]) for topic in covid_topics]\n",
    "\n",
    "news_observed_avgs_oct_3 = [np.mean(topic[\"observed_ratings_oct3\"]) for topic in news_topics]\n",
    "leg_observed_avgs_oct_3 = [np.mean(topic[\"observed_ratings_oct3\"]) for topic in leg_topics]\n",
    "covid_observed_avgs_oct_3 = [np.mean(topic[\"observed_ratings_oct3\"]) for topic in covid_topics]\n",
    "\n",
    "news_observed_avgs_oct_18 = [np.mean(topic[\"observed_ratings_oct18\"]) for topic in news_topics_oct_18]\n",
    "leg_observed_avgs_oct_18 = [np.mean(topic[\"observed_ratings_oct18\"]) for topic in leg_topics_oct_18]\n",
    "covid_observed_avgs_oct_18 = [np.mean(topic[\"observed_ratings_oct18\"]) for topic in covid_topics_oct_18]\n",
    "\n",
    "news_intrusion_avgs = [np.mean(topic[\"intrusion_ratings\"]) for topic in news_topics]\n",
    "leg_intrusion_avgs = [np.mean(topic[\"intrusion_ratings\"]) for topic in leg_topics]\n",
    "covid_intrusion_avgs = [np.mean(topic[\"intrusion_ratings\"]) for topic in covid_topics]\n",
    "\n",
    "news_intrusion_avgs_oct_18 = [np.mean(topic[\"intrusion_ratings\"]) for topic in news_topics_oct_18]\n",
    "leg_intrusion_avgs_oct_18 = [np.mean(topic[\"intrusion_ratings\"]) for topic in leg_topics_oct_18]\n",
    "covid_intrusion_avgs_oct_18 = [np.mean(topic[\"intrusion_ratings\"]) for topic in covid_topics_oct_18]\n",
    "\n",
    "print(len(news_observed_avgs), len(leg_observed_avgs), len(covid_observed_avgs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,topic in enumerate(news_topics):\n",
    "    print(topic[\"terms\"])\n",
    "    print(news_npmi_scores[idx])\n",
    "    print(news_observed_avgs[idx])\n",
    "    print(wiki_news_npmi_scores[idx])\n",
    "    print(\"-------------\")\n",
    "    \n",
    "for idx,topic in enumerate(news_topics_oct_18):\n",
    "    print(topic[\"terms\"])\n",
    "    print(news_npmi_scores_oct18[idx])\n",
    "    print(news_observed_avgs_oct_18[idx])\n",
    "    print(wiki_news_npmi_scores_oct18[idx])\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import file_handling as fh\n",
    "ref_vocab_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/news_group.vocab.json\"\n",
    "ref_counts_file = \"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/ref_count_outputs/news_group.npz\"\n",
    "ref_vocab = fh.read_json(ref_vocab_file)\n",
    "ref_counts = fh.load_sparse(ref_counts_file).tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compute_npmi import compute_npmi_at_n_for_topic\n",
    "compute_npmi_at_n_for_topic(['god', 'people', 'jesus', 'christian', 'bible', 'religion', 'church', 'word', 'point', 'faith'], ref_vocab, ref_counts, n=10, cols_to_skip=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(covid_npmi_scores)\n",
    "print(covid_npmi_scores_oct18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the ratings task with NPMI for the first set of data\n",
    "print(scipy.stats.spearmanr(news_observed_avgs, news_npmi_scores), np.mean(news_npmi_scores))\n",
    "print(scipy.stats.spearmanr(leg_observed_avgs, leg_npmi_scores), np.mean(leg_npmi_scores))\n",
    "print(scipy.stats.spearmanr(covid_observed_avgs, covid_npmi_scores), np.mean(covid_npmi_scores))\n",
    "print(\"========INTRUSION=========\")\n",
    "print(scipy.stats.spearmanr(news_intrusion_avgs, news_npmi_scores), np.mean(news_npmi_scores))\n",
    "print(scipy.stats.spearmanr(leg_intrusion_avgs, leg_npmi_scores), np.mean(leg_npmi_scores))\n",
    "print(scipy.stats.spearmanr(covid_intrusion_avgs, covid_npmi_scores), np.mean(covid_npmi_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare ratings data from october 3 with the NPMI scores\n",
    "print(scipy.stats.spearmanr(news_observed_avgs_oct_3, news_npmi_scores), np.mean(news_npmi_scores))\n",
    "print(scipy.stats.spearmanr(leg_observed_avgs_oct_3, leg_npmi_scores), np.mean(leg_npmi_scores))\n",
    "print(scipy.stats.spearmanr(covid_observed_avgs_oct_3, covid_npmi_scores), np.mean(covid_npmi_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing ratings task with NPMI for the second set of data\n",
    "print(scipy.stats.spearmanr(news_observed_avgs_oct_18, news_npmi_scores_oct18), np.mean(news_npmi_scores_oct18))\n",
    "print(scipy.stats.spearmanr(leg_observed_avgs_oct_18, leg_npmi_scores_oct18), np.mean(leg_npmi_scores_oct18))\n",
    "print(scipy.stats.spearmanr(covid_observed_avgs_oct_18, covid_npmi_scores_oct18), np.mean(covid_npmi_scores_oct18))\n",
    "print(\"========INTRUSION=========\")\n",
    "print(scipy.stats.spearmanr(news_intrusion_avgs_oct_18, news_npmi_scores_oct18), np.mean(news_npmi_scores_oct18))\n",
    "print(scipy.stats.spearmanr(leg_intrusion_avgs_oct_18, leg_npmi_scores_oct18), np.mean(leg_npmi_scores_oct18))\n",
    "print(scipy.stats.spearmanr(covid_intrusion_avgs_oct_18, covid_npmi_scores_oct18), np.mean(covid_npmi_scores_oct18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try appending the 2 dataset collections together\n",
    "all_news_avgs = news_observed_avgs_oct_3 + news_observed_avgs_oct_18\n",
    "all_leg_avgs = leg_observed_avgs_oct_3 + leg_observed_avgs_oct_18\n",
    "all_covid_avgs = covid_observed_avgs_oct_3 + covid_observed_avgs_oct_18\n",
    "\n",
    "all_news_intrusion_avgs = news_intrusion_avgs + news_intrusion_avgs_oct_18\n",
    "all_leg_intrusion_avgs = leg_intrusion_avgs + leg_intrusion_avgs_oct_18\n",
    "all_covid_intrusion_avgs = covid_intrusion_avgs + covid_intrusion_avgs_oct_18\n",
    "\n",
    "all_news_npmi = news_npmi_scores + news_npmi_scores_oct18\n",
    "all_leg_npmi = leg_npmi_scores + leg_npmi_scores_oct18\n",
    "all_covid_npmi = covid_npmi_scores + covid_npmi_scores_oct18\n",
    "\n",
    "all_wiki_news_npmi = wiki_news_npmi_scores + wiki_news_npmi_scores_oct18\n",
    "all_wiki_leg_npmi = wiki_leg_npmi_scores + wiki_leg_npmi_scores_oct18\n",
    "all_wiki_covid_npmi = wiki_covid_npmi_scores + wiki_covid_npmi_scores_oct18\n",
    "\n",
    "print(scipy.stats.spearmanr(all_news_avgs, all_news_npmi), np.mean(all_news_npmi))\n",
    "print(scipy.stats.spearmanr(all_leg_avgs, all_leg_npmi), np.mean(all_leg_npmi))\n",
    "print(scipy.stats.spearmanr(all_covid_avgs, all_covid_npmi), np.mean(all_covid_npmi))\n",
    "print(\"========INTRUSION=========\")\n",
    "print(scipy.stats.spearmanr(all_news_intrusion_avgs, all_news_npmi), np.mean(all_news_npmi))\n",
    "print(scipy.stats.spearmanr(all_leg_intrusion_avgs, all_leg_npmi), np.mean(all_leg_npmi))\n",
    "print(scipy.stats.spearmanr(all_covid_intrusion_avgs, all_covid_npmi), np.mean(all_covid_npmi))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_tuples = [\n",
    "    (all_news_avgs, all_news_npmi),\n",
    "    (all_news_intrusion_avgs, all_news_npmi),\n",
    "    (all_leg_avgs, all_leg_npmi),\n",
    "    (all_leg_intrusion_avgs, all_leg_npmi),\n",
    "    (all_covid_avgs, all_covid_npmi),\n",
    "    (all_covid_intrusion_avgs, all_covid_npmi),\n",
    "]\n",
    "for analysis_tuple in analysis_tuples:\n",
    "    stats = scipy.stats.spearmanr(analysis_tuple[0], analysis_tuple[1])\n",
    "    print(f\"{stats.correlation:.4f} ({stats.pvalue:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scipy.stats.spearmanr(news_observed_avgs, wiki_news_npmi_scores), np.mean(wiki_news_npmi_scores))\n",
    "print(scipy.stats.spearmanr(leg_observed_avgs, wiki_leg_npmi_scores), np.mean(wiki_leg_npmi_scores))\n",
    "print(scipy.stats.spearmanr(covid_observed_avgs, wiki_covid_npmi_scores), np.mean(wiki_covid_npmi_scores))\n",
    "print(\"========INTRUSION=========\")\n",
    "print(scipy.stats.spearmanr(news_intrusion_avgs, wiki_news_npmi_scores), np.mean(wiki_news_npmi_scores))\n",
    "print(scipy.stats.spearmanr(leg_intrusion_avgs, wiki_leg_npmi_scores), np.mean(wiki_leg_npmi_scores))\n",
    "print(scipy.stats.spearmanr(covid_intrusion_avgs, wiki_covid_npmi_scores), np.mean(wiki_covid_npmi_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_tuples = [\n",
    "    (all_news_avgs, all_wiki_news_npmi),\n",
    "    (all_news_intrusion_avgs, all_wiki_news_npmi),\n",
    "    (all_leg_avgs, all_wiki_leg_npmi),\n",
    "    (all_leg_intrusion_avgs, all_wiki_leg_npmi),\n",
    "    (all_covid_avgs, all_wiki_covid_npmi),\n",
    "    (all_covid_intrusion_avgs, all_wiki_covid_npmi),\n",
    "]\n",
    "for analysis_tuple in analysis_tuples:\n",
    "    stats = scipy.stats.spearmanr(analysis_tuple[0], analysis_tuple[1])\n",
    "    print(f\"{stats.correlation:.4f} ({stats.pvalue:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Notes:\n",
    "The NPMI score averages were all relatively close, but with the covid model being slightly higher probably\n",
    "due to a more 'specialized' vocabulary. Does this mean the models were of similar respective quality?\n",
    "- Observed\n",
    "News correlated well and in line with news correlations found in the original Newman paper\n",
    "Legislation was next higher and covid actually had a negative correlation\n",
    "\n",
    "The lack of correlation of the covid data proves that the crowd sourced annotators were likely 'pretending'\n",
    "or assuming the topics were correct but their lack of medical knowledge prohibited that\n",
    "\n",
    "*It's very unclear why the intrusion scores correlate so poorly for the news dataset - WHY?\n",
    "* Meanwhile the legislation scores were almost identical - WHY?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.models.word2vec as w2v\n",
    "\n",
    "news_w2v = w2v.Word2Vec.load(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/embeddings/news_group.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_w2v = w2v.Word2Vec.load(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/embeddings/115_legislation.w2v\")\n",
    "covid_w2v = w2v.Word2Vec.load(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/embeddings/covid.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "def calculate_w2v_cos_avg_for_topic(topic, model):\n",
    "    \n",
    "    cos_sims = []\n",
    "    for idx, term in enumerate(topic):\n",
    "        for idx2, term2 in enumerate(topic[idx + 1:]):\n",
    "            if term in model and term2 in model:\n",
    "                cosine_similarity = 1 - cosine(model[term], model[term2])\n",
    "                cos_sims.append(cosine_similarity)\n",
    "            else:\n",
    "                print(f\"Terms {term}, {term2} not found in model\")\n",
    "\n",
    "    return np.mean(cos_sims)\n",
    "            \n",
    "news_w2v_scores = []\n",
    "leg_w2v_scores = []\n",
    "covid_w2v_scores = []\n",
    "\n",
    "def calculate_w2v_scores(topics, w2v_model):\n",
    "    scores = []\n",
    "    for topic in topics:\n",
    "        score = calculate_w2v_cos_avg_for_topic(topic[\"terms\"], w2v_model)\n",
    "        scores.append(score)\n",
    "        topic[\"internal_w2v_cos\"] = score\n",
    "    return scores\n",
    "\n",
    "news_w2v_scores = calculate_w2v_scores(news_topics, news_w2v)\n",
    "leg_w2v_scores = calculate_w2v_scores(leg_topics, leg_w2v)\n",
    "covid_w2v_scores = calculate_w2v_scores(covid_topics, covid_w2v)\n",
    "\n",
    "news_w2v_scores_oct_18 = calculate_w2v_scores(news_topics_oct_18, news_w2v)\n",
    "leg_w2v_scores_oct_18 = calculate_w2v_scores(leg_topics_oct_18, leg_w2v)\n",
    "covid_w2v_scores_oct_18 = calculate_w2v_scores(covid_topics_oct_18, covid_w2v)\n",
    "\"\"\"\n",
    "for topic in news_topics:\n",
    "    score = calculate_w2v_cos_avg_for_topic(topic[\"terms\"], news_w2v)\n",
    "    news_w2v_scores.append(score)\n",
    "    topic[\"internal_w2v_cos\"] = score\n",
    "    #print(topic[\"terms\"], topic[\"internal_w2v_cos\"])\n",
    "\n",
    "print(\"-------------------\")\n",
    "    \n",
    "for topic in leg_topics:\n",
    "    score = calculate_w2v_cos_avg_for_topic(topic[\"terms\"], leg_w2v)\n",
    "    leg_w2v_scores.append(score)\n",
    "    topic[\"internal_w2v_cos\"] = score\n",
    "    #print(topic[\"terms\"], topic[\"internal_w2v_cos\"])\n",
    "    \n",
    "print(\"-------------------\")\n",
    "    \n",
    "for topic in covid_topics:\n",
    "    score = calculate_w2v_cos_avg_for_topic(topic[\"terms\"], covid_w2v)\n",
    "    covid_w2v_scores.append(score)\n",
    "    topic[\"internal_w2v_cos\"] = score\n",
    "    #print(topic[\"terms\"], topic[\"internal_w2v_cos\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "wiki_model_w2v = KeyedVectors.load_word2vec_format(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/embeddings/enwiki_20180420_win10_100d.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_wiki_scores = [calculate_w2v_cos_avg_for_topic(topic[\"terms\"], wiki_model_w2v) for topic in news_topics]\n",
    "leg_wiki_scores = [calculate_w2v_cos_avg_for_topic(topic[\"terms\"], wiki_model_w2v) for topic in leg_topics]\n",
    "covid_wiki_scores = [calculate_w2v_cos_avg_for_topic(topic[\"terms\"], wiki_model_w2v) for topic in covid_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_wiki_scores_oct_18 = [calculate_w2v_cos_avg_for_topic(topic[\"terms\"], wiki_model_w2v) for topic in news_topics_oct_18]\n",
    "leg_wiki_scores_oct_18 = [calculate_w2v_cos_avg_for_topic(topic[\"terms\"], wiki_model_w2v) for topic in leg_topics_oct_18]\n",
    "covid_wiki_scores_oct_18 = [calculate_w2v_cos_avg_for_topic(topic[\"terms\"], wiki_model_w2v) for topic in covid_topics_oct_18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=========NPMI==========\")\n",
    "print(scipy.stats.spearmanr(news_observed_avgs, news_npmi_scores), np.mean(news_npmi_scores))\n",
    "print(scipy.stats.spearmanr(leg_observed_avgs, leg_npmi_scores), np.mean(leg_npmi_scores))\n",
    "print(scipy.stats.spearmanr(covid_observed_avgs, covid_npmi_scores), np.mean(covid_npmi_scores))\n",
    "print(\"========INTRUSION=========\")\n",
    "print(scipy.stats.spearmanr(news_intrusion_avgs, news_npmi_scores), np.mean(news_npmi_scores))\n",
    "print(scipy.stats.spearmanr(leg_intrusion_avgs, leg_npmi_scores), np.mean(leg_npmi_scores))\n",
    "print(scipy.stats.spearmanr(covid_intrusion_avgs, covid_npmi_scores), np.mean(covid_npmi_scores))\n",
    "\n",
    "print(\"========WORD 2 VEC========\")\n",
    "print(scipy.stats.spearmanr(news_observed_avgs, news_w2v_scores), np.mean(news_w2v_scores))\n",
    "print(scipy.stats.spearmanr(leg_observed_avgs, leg_w2v_scores), np.mean(leg_w2v_scores))\n",
    "print(scipy.stats.spearmanr(covid_observed_avgs, covid_w2v_scores), np.mean(covid_w2v_scores))\n",
    "print(\"========INTRUSION=========\")\n",
    "print(scipy.stats.spearmanr(news_intrusion_avgs, news_w2v_scores), np.mean(news_w2v_scores))\n",
    "print(scipy.stats.spearmanr(leg_intrusion_avgs, leg_w2v_scores), np.mean(leg_w2v_scores))\n",
    "print(scipy.stats.spearmanr(covid_intrusion_avgs, covid_w2v_scores), np.mean(covid_w2v_scores))\n",
    "\n",
    "print(\"========WIKI VECTORS========\")\n",
    "print(scipy.stats.spearmanr(news_observed_avgs, news_wiki_scores), np.mean(news_wiki_scores))\n",
    "print(scipy.stats.spearmanr(leg_observed_avgs, leg_wiki_scores), np.mean(leg_wiki_scores))\n",
    "print(scipy.stats.spearmanr(covid_observed_avgs, covid_wiki_scores), np.mean(covid_wiki_scores))\n",
    "print(\"========INTRUSION=========\")\n",
    "print(scipy.stats.spearmanr(news_intrusion_avgs, news_wiki_scores), np.mean(news_wiki_scores))\n",
    "print(scipy.stats.spearmanr(leg_intrusion_avgs, leg_wiki_scores), np.mean(leg_wiki_scores))\n",
    "print(scipy.stats.spearmanr(covid_intrusion_avgs, covid_wiki_scores), np.mean(covid_wiki_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test just the october 18 data\n",
    "print(\"========WORD 2 VEC========\")\n",
    "print(scipy.stats.spearmanr(news_observed_avgs_oct_18, news_w2v_scores_oct_18), np.mean(news_w2v_scores_oct_18))\n",
    "print(scipy.stats.spearmanr(leg_observed_avgs_oct_18, leg_w2v_scores_oct_18), np.mean(leg_w2v_scores_oct_18))\n",
    "print(scipy.stats.spearmanr(covid_observed_avgs_oct_18, covid_w2v_scores_oct_18), np.mean(covid_w2v_scores_oct_18))\n",
    "print(\"========INTRUSION=========\")\n",
    "print(scipy.stats.spearmanr(news_intrusion_avgs_oct_18, news_w2v_scores_oct_18), np.mean(news_w2v_scores_oct_18))\n",
    "print(scipy.stats.spearmanr(leg_intrusion_avgs_oct_18, leg_w2v_scores_oct_18), np.mean(leg_w2v_scores_oct_18))\n",
    "print(scipy.stats.spearmanr(covid_intrusion_avgs_oct_18, covid_w2v_scores_oct_18), np.mean(covid_w2v_scores_oct_18))\n",
    "\n",
    "print(\"========WIKI VECTORS========\")\n",
    "print(scipy.stats.spearmanr(news_observed_avgs_oct_18, news_wiki_scores_oct_18), np.mean(news_wiki_scores_oct_18))\n",
    "print(scipy.stats.spearmanr(leg_observed_avgs_oct_18, leg_wiki_scores_oct_18), np.mean(leg_wiki_scores_oct_18))\n",
    "print(scipy.stats.spearmanr(covid_observed_avgs_oct_18, covid_wiki_scores_oct_18), np.mean(covid_wiki_scores_oct_18))\n",
    "print(\"========INTRUSION=========\")\n",
    "print(scipy.stats.spearmanr(news_intrusion_avgs_oct_18, news_wiki_scores_oct_18), np.mean(news_wiki_scores_oct_18))\n",
    "print(scipy.stats.spearmanr(leg_intrusion_avgs_oct_18, leg_wiki_scores_oct_18), np.mean(leg_wiki_scores_oct_18))\n",
    "print(scipy.stats.spearmanr(covid_intrusion_avgs_oct_18, covid_wiki_scores_oct_18), np.mean(covid_wiki_scores_oct_18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the combined data\n",
    "combined_news_w2v_scores = news_w2v_scores + news_w2v_scores_oct_18\n",
    "combined_leg_w2v_scores = leg_w2v_scores + leg_w2v_scores_oct_18\n",
    "combined_covid_w2v_scores = covid_w2v_scores + covid_w2v_scores_oct_18\n",
    "\n",
    "combined_news_wiki_scores = news_wiki_scores + news_wiki_scores_oct_18\n",
    "combined_leg_wiki_scores = leg_wiki_scores + leg_wiki_scores_oct_18\n",
    "combined_covid_wiki_scores = covid_wiki_scores + covid_wiki_scores_oct_18\n",
    "\n",
    "print(\"========WORD 2 VEC========\")\n",
    "print(scipy.stats.spearmanr(all_news_avgs, combined_news_w2v_scores), np.mean(combined_news_w2v_scores))\n",
    "print(scipy.stats.spearmanr(all_leg_avgs, combined_leg_w2v_scores), np.mean(combined_leg_w2v_scores))\n",
    "print(scipy.stats.spearmanr(all_covid_avgs, combined_covid_w2v_scores), np.mean(combined_covid_w2v_scores))\n",
    "print(\"========INTRUSION=========\")\n",
    "print(scipy.stats.spearmanr(all_news_intrusion_avgs, combined_news_w2v_scores), np.mean(combined_news_w2v_scores))\n",
    "print(scipy.stats.spearmanr(all_leg_intrusion_avgs, combined_leg_w2v_scores ), np.mean(combined_leg_w2v_scores ))\n",
    "print(scipy.stats.spearmanr(all_covid_intrusion_avgs, combined_covid_w2v_scores), np.mean(combined_covid_w2v_scores))\n",
    "\n",
    "print(\"========WIKI VECTORS========\")\n",
    "print(scipy.stats.spearmanr(all_news_avgs, combined_news_wiki_scores), np.mean(combined_news_wiki_scores))\n",
    "print(scipy.stats.spearmanr(all_leg_avgs, combined_leg_wiki_scores), np.mean(combined_leg_wiki_scores))\n",
    "print(scipy.stats.spearmanr(all_covid_avgs, combined_covid_wiki_scores), np.mean(combined_covid_wiki_scores))\n",
    "print(\"========INTRUSION=========\")\n",
    "print(scipy.stats.spearmanr(all_news_intrusion_avgs, combined_news_wiki_scores), np.mean(combined_news_wiki_scores))\n",
    "print(scipy.stats.spearmanr(all_leg_intrusion_avgs, combined_leg_wiki_scores), np.mean(combined_leg_wiki_scores))\n",
    "print(scipy.stats.spearmanr(all_covid_intrusion_avgs, combined_covid_wiki_scores), np.mean(combined_covid_wiki_scores))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Internal W2V\n",
    "analysis_tuples = [\n",
    "    (all_news_avgs, combined_news_w2v_scores),\n",
    "    (all_news_intrusion_avgs, combined_news_w2v_scores),\n",
    "    (all_leg_avgs, combined_leg_w2v_scores),\n",
    "    (all_leg_intrusion_avgs, combined_leg_w2v_scores),\n",
    "    (all_covid_avgs, combined_covid_w2v_scores),\n",
    "    (all_covid_intrusion_avgs, combined_covid_w2v_scores),\n",
    "]\n",
    "for analysis_tuple in analysis_tuples:\n",
    "    stats = scipy.stats.spearmanr(analysis_tuple[0], analysis_tuple[1])\n",
    "    print(f\"{stats.correlation:.4f} ({stats.pvalue:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do External W2V\n",
    "analysis_tuples = [\n",
    "    (all_news_avgs, combined_news_wiki_scores),\n",
    "    (all_news_intrusion_avgs, combined_news_wiki_scores),\n",
    "    (all_leg_avgs, combined_leg_wiki_scores),\n",
    "    (all_leg_intrusion_avgs, combined_leg_wiki_scores),\n",
    "    (all_covid_avgs, combined_covid_wiki_scores),\n",
    "    (all_covid_intrusion_avgs, combined_covid_wiki_scores),\n",
    "]\n",
    "for analysis_tuple in analysis_tuples:\n",
    "    stats = scipy.stats.spearmanr(analysis_tuple[0], analysis_tuple[1])\n",
    "    print(f\"{stats.correlation:.4f} ({stats.pvalue:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save the topics scores\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def add_eval_scores(topics, external_npmi, internal_npmi, external_w2v, internal_w2v):\n",
    "    for idx, topic in enumerate(topics):\n",
    "        topic[\"external_npmi\"] = external_npmi[idx]\n",
    "        topic[\"internal_npmi\"] = internal_npmi[idx]\n",
    "        topic[\"external_w2v\"] = external_w2v[idx]\n",
    "        topic[\"internal_w2v\"] = internal_npmi[idx]\n",
    "        \n",
    "add_eval_scores(news_topics, wiki_news_npmi_scores, news_npmi_scores, news_w2v_scores, news_wiki_scores)\n",
    "\n",
    "add_eval_scores(leg_topics, wiki_leg_npmi_scores, leg_npmi_scores, leg_w2v_scores, leg_wiki_scores)\n",
    "\n",
    "add_eval_scores(covid_topics, wiki_covid_npmi_scores, covid_npmi_scores, covid_w2v_scores, covid_wiki_scores)\n",
    "# Apply this to october 18\n",
    "add_eval_scores(news_topics_oct_18, wiki_news_npmi_scores_oct18, news_npmi_scores_oct18, news_w2v_scores_oct_18, news_wiki_scores_oct_18)\n",
    "\n",
    "add_eval_scores(leg_topics_oct_18, wiki_leg_npmi_scores_oct18, leg_npmi_scores_oct18, leg_w2v_scores_oct_18, leg_wiki_scores_oct_18)\n",
    "\n",
    "add_eval_scores(covid_topics_oct_18, wiki_covid_npmi_scores_oct18, covid_npmi_scores_oct18, covid_w2v_scores_oct_18, covid_wiki_scores_oct_18)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(news_topics, open(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/news_ratings_with_eval.json\", \"w\"))\n",
    "json.dump(leg_topics, open(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/leg_ratings_with_eval.json\", \"w\"))\n",
    "json.dump(covid_topics, open(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/covid_ratings_with_eval.json\", \"w\"))\n",
    "\n",
    "json.dump(news_topics_oct_18, open(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/oct_18/news_ratings_with_eval_oct_18.json\", \"w\"))\n",
    "json.dump(leg_topics_oct_18, open(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/oct_18/leg_ratings_with_eval_oct_18.json\", \"w\"))\n",
    "json.dump(covid_topics_oct_18, open(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/oct_18/covid_ratings_with_eval_oct_18.json\", \"w\"))\n",
    "\n",
    "json.dump(news_topics + news_topics_oct_18, open(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/news_ratings_with_eval_combined.json\", \"w\"))\n",
    "json.dump(leg_topics + leg_topics_oct_18, open(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/leg_ratings_with_eval_combined.json\", \"w\"))\n",
    "json.dump(covid_topics + covid_topics_oct_18, open(\"/Users/hiancheong/Personal/grad/UMD/comp_ling/topics_evaluation/covid_ratings_with_eval_combined.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Breaking this down in a chart will make it easier to visualize\n",
    "- The lower P-value can only be enhanced by more data\n",
    "- Should I just collect more, or tweak things to be more understandable or more consistent?\n",
    "- It should be easier to get more 'accurate results' if I just do the top 5 words of a topic\n",
    "for the observation scores\n",
    "- Get another 7 responses to the prolific surveys to get up to 15 each (another $40). The intrusion data should\n",
    "stay consistent even if we need to go get even more data and tweak the observed experiment\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scipy.stats.spearmanr(news_observed_avgs, news_wiki_scores), np.mean(news_wiki_scores))\n",
    "print(scipy.stats.spearmanr(leg_observed_avgs, leg_wiki_scores), np.mean(leg_wiki_scores))\n",
    "print(scipy.stats.spearmanr(covid_observed_avgs, covid_wiki_scores), np.mean(covid_wiki_scores))\n",
    "print(\"========INTRUSION=========\")\n",
    "print(scipy.stats.spearmanr(news_intrusion_avgs, news_wiki_scores), np.mean(news_wiki_scores))\n",
    "print(scipy.stats.spearmanr(leg_intrusion_avgs, leg_wiki_scores), np.mean(leg_wiki_scores))\n",
    "print(scipy.stats.spearmanr(covid_intrusion_avgs, covid_wiki_scores), np.mean(covid_wiki_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_plot(news, leg, covid, m_news, m_leg, m_covid, xlabel=\"Human\", ylabel=\"Machine\"):\n",
    "    # NOTE: the m stands for 'machine'\n",
    "    fig, axs = plt.subplots(3, sharex=False, sharey=False, gridspec_kw={'hspace': 1})\n",
    "\n",
    "    axs[0].scatter(news, m_news)\n",
    "    axs[0].set_title(\"News\")\n",
    "    axs[1].scatter(leg, m_leg)\n",
    "    axs[1].set_title(\"Legislation\")\n",
    "    axs[2].scatter(covid, m_covid)\n",
    "    axs[2].set_title(\"Covid\")\n",
    "\n",
    "    for subplot in axs.flat:\n",
    "        subplot.set(xlabel=xlabel, ylabel=ylabel)\n",
    "#plt.ylabel(\"wiki_sim_scores\")\n",
    "#plt.show()\n",
    "generate_plot(\n",
    "    news_observed_avgs,\n",
    "    leg_observed_avgs,\n",
    "    covid_observed_avgs,\n",
    "    news_npmi_scores,\n",
    "    leg_npmi_scores,\n",
    "    covid_npmi_scores,\n",
    "    xlabel=\"Human Observed\", ylabel=\"Internal NPMI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot out distribution of good vs bad topics for either set\n",
    "\"\"\"\n",
    "#fig = plt.figure(figsize =(16, 7)) \n",
    "# Creating axes instance \n",
    "#ax = fig.add_axes([0, 0, 1, 1]) \n",
    "\n",
    "%matplotlib inline\n",
    "# Import libraries \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "\"\"\"\n",
    "analysis_tuples = [\n",
    "    (all_news_avgs, all_wiki_news_npmi),\n",
    "    (all_news_intrusion_avgs, all_wiki_news_npmi),\n",
    "    (all_leg_avgs, all_wiki_leg_npmi),\n",
    "    (all_leg_intrusion_avgs, all_wiki_leg_npmi),\n",
    "    (all_covid_avgs, all_wiki_covid_npmi),\n",
    "    (all_covid_intrusion_avgs, all_wiki_covid_npmi),\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "def create_scatter(ax, x_data, y_data, title, x_label, y_label):\n",
    "    # show plot \n",
    "    spearman = scipy.stats.spearmanr(x_data, y_data)\n",
    "\n",
    "    ax.scatter(x_data, y_data)\n",
    "    ax.set_title(title + f\" r={spearman.correlation:.3f} (p={spearman.pvalue:.2f})\")\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(8,3)\n",
    "\n",
    "# RATINGS INTERNAL NPMI\n",
    "create_scatter(axs[0][0], all_news_avgs, all_news_npmi,\n",
    "               \"News Ratings vs Internal NPMI\", \"News Ratings\", \"News Internal NPMI\")\n",
    "create_scatter(axs[0][1], all_leg_avgs, all_leg_npmi,\n",
    "               \"Legislation Ratings vs Internal NPMI\", \"Legislation Ratings\", \"Legislation Internal NPMI\")\n",
    "create_scatter(axs[0][2], all_covid_avgs, all_covid_npmi,\n",
    "               \"Covid Ratings vs Internal NPMI\", \"Covid Ratings\", \"Covid Internal NPMI\")\n",
    "\n",
    "# INTRUSION INTERNAL NPMI\n",
    "create_scatter(axs[1][0], all_news_intrusion_avgs, all_news_npmi,\n",
    "               \"News Intrusion vs Internal NPMI\", \"News Intrusion\", \"News Internal NPMI\")\n",
    "create_scatter(axs[1][1], all_leg_intrusion_avgs, all_leg_npmi,\n",
    "               \"Legislation Intrusion vs Internal NPMI\", \"Legislation Intrusion\", \"Legislation Internal NPMI\")\n",
    "create_scatter(axs[1][2], all_covid_intrusion_avgs, all_covid_npmi,\n",
    "               \"Covid Intrusion vs Internal NPMI\", \"Covid Intrusion\", \"Covid Internal NPMI\")\n",
    "\n",
    "# RATINGS EXTERNAL NPMI\n",
    "create_scatter(axs[2][0], all_news_avgs, all_wiki_news_npmi,\n",
    "               \"News Ratings vs External NPMI\", \"News Ratings\", \"News External NPMI\")\n",
    "create_scatter(axs[2][1], all_leg_avgs, all_wiki_leg_npmi,\n",
    "               \"Legislation Ratings vs External NPMI\", \"Legislation Ratings\", \"Legislation External NPMI\")\n",
    "create_scatter(axs[2][2], all_covid_avgs, all_wiki_covid_npmi,\n",
    "               \"Covid Ratings vs External NPMI\", \"Covid Ratings\", \"Covid External NPMI\")\n",
    "\n",
    "# INTRUSION EXTERNAL NPMI\n",
    "create_scatter(axs[3][0], all_news_intrusion_avgs, all_wiki_news_npmi,\n",
    "               \"News Intrusion vs External NPMI\", \"News Intrusion\", \"News External NPMI\")\n",
    "create_scatter(axs[3][1], all_leg_intrusion_avgs, all_wiki_leg_npmi,\n",
    "               \"Legislation Intrusion vs External NPMI\", \"Legislation Intrusion\", \"Legislation External NPMI\")\n",
    "create_scatter(axs[3][2], all_covid_intrusion_avgs, all_wiki_covid_npmi,\n",
    "               \"Covid Intrusion vs External NPMI\", \"Covid Intrusion\", \"Covid External NPMI\")\n",
    "\n",
    "# RATINGS INTERNAL W2V\n",
    "create_scatter(axs[4][0], all_news_avgs, combined_news_w2v_scores,\n",
    "               \"News Ratings vs Internal W2V\", \"News Ratings\", \"News Internal W2V\")\n",
    "create_scatter(axs[4][1], all_leg_avgs, combined_leg_w2v_scores,\n",
    "               \"Legislation Ratings vs Internal W2V\", \"Legislation Ratings\", \"Legislation Internal W2V\")\n",
    "create_scatter(axs[4][2], all_covid_avgs, combined_covid_w2v_scores,\n",
    "               \"Covid Ratings vs Internal W2V\", \"Covid Ratings\", \"Covid Internal W2V\")\n",
    "\n",
    "# INTRUSION INTERNAL W2V\n",
    "create_scatter(axs[5][0], all_news_intrusion_avgs, combined_news_w2v_scores,\n",
    "               \"News Intrusion vs Internal W2V\", \"News Intrusion\", \"News Internal W2V\")\n",
    "create_scatter(axs[5][1], all_leg_intrusion_avgs, combined_leg_w2v_scores,\n",
    "               \"Legislation Intrusion vs Internal W2V\", \"Legislation Intrusion\", \"Legislation Internal W2V\")\n",
    "create_scatter(axs[5][2], all_covid_intrusion_avgs, combined_covid_w2v_scores,\n",
    "               \"Covid Intrusion vs Internal W2V\", \"Covid Intrusion\", \"Covid Internal W2V\")\n",
    "\n",
    "# RATINGS EXTERNAL W2V\n",
    "create_scatter(axs[6][0], all_news_avgs, combined_news_wiki_scores,\n",
    "               \"News Ratings vs External W2V\", \"News Ratings\", \"News External W2V\")\n",
    "create_scatter(axs[6][1], all_leg_avgs, combined_leg_wiki_scores,\n",
    "               \"Legislation Ratings vs External W2V\", \"Legislation Ratings\", \"Legislation External W2V\")\n",
    "create_scatter(axs[6][2], all_covid_avgs, combined_covid_wiki_scores,\n",
    "               \"Covid Ratings vs External W2V\", \"Covid Ratings\", \"Covid External W2V\")\n",
    "\n",
    "# INTRUSION EXTERNAL W2V\n",
    "create_scatter(axs[7][0], all_news_intrusion_avgs, combined_news_wiki_scores,\n",
    "               \"News Intrusion vs External W2V\", \"News Intrusion\", \"News External W2V\")\n",
    "create_scatter(axs[7][1], all_leg_intrusion_avgs, combined_leg_wiki_scores,\n",
    "               \"Legislation Intrusion vs External W2V\", \"Legislation Intrusion\", \"Legislation External W2V\")\n",
    "create_scatter(axs[7][2], all_covid_intrusion_avgs, combined_covid_wiki_scores,\n",
    "               \"Covid Intrusion vs External W2V\", \"Covid Intrusion\", \"Covid External W2V\")\n",
    "\n",
    "#create_ratings_scatter(axs[0][1], leg_ratings, \"Legislation Ratings\")\n",
    "#create_ratings_scatter(axs[0][2], covid_ratings, \"Covid Ratings\")\n",
    "\n",
    "#create_intrusion_scatter(axs[1][0], news_intrusion, \"News Intrusion\")\n",
    "#create_intrusion_scatter(axs[1][1], leg_intrusion, \"Legislation Intrusion\")\n",
    "#create_intrusion_scatter(axs[1][2], covid_intrusion, \"Covid Intrusion\")\n",
    "\n",
    "#create_ratings_scatter(axs[2][0], news_ratings_oct_18, \"News Ratings (Oct 18)\")\n",
    "#create_ratings_scatter(axs[2][1], leg_ratings_oct_18, \"Legislation Ratings (Oct 18)\")\n",
    "#create_ratings_scatter(axs[2][2], covid_ratings_oct_18, \"Covid Ratings (Oct 18)\")\n",
    "\n",
    "#create_intrusion_scatter(axs[3][0], news_intrusion_oct_18, \"News Intrusion (Oct 18)\", True)\n",
    "#create_intrusion_scatter(axs[3][1], leg_intrusion_oct_18, \"Legislation Intrusion (Oct 18)\", True)\n",
    "#create_intrusion_scatter(axs[3][2], covid_intrusion_oct_18, \"Covid Intrusion (Oct 18)\", True)\n",
    "\n",
    "fig.set_size_inches(16, 28)\n",
    "fig.tight_layout(pad=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
